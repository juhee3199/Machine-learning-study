{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aghKlTJsFVHU"
   },
   "source": [
    "# 문제 1.  활성함수 정의하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAZ-Qp6tFVHn"
   },
   "source": [
    "- 이번 주차에서 공부한 활성함수(Sigmoid, RELU, tanh함수)를 직접 정의해 봅시다\n",
    "- numpy method 이용해서 함수 정의하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayfZrpglFVHp"
   },
   "source": [
    "### 1) Sigmoid함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6TKAYHpzFVHr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 +np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXMIugRpFVHt"
   },
   "source": [
    "### 2) RELU함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wq8sRMBEFVHu"
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hACIEHP-FVHv"
   },
   "source": [
    "### 3) tanh함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2rO2PVVvFVHw"
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MH_qZfD9FVHx"
   },
   "source": [
    "# 문제 2. 신경망 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhaCqofZFVHx"
   },
   "source": [
    "- tensorflow이용하여 단순 신경망 구현하는 방법을(다음주차) 공부하기 전 numpy를 이용하여 신경망을 구현해 봅시다\n",
    "- summation 구할 때 np.dot 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "d5PxKnagFVHy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(5)\n",
    "\n",
    "W1 = np.random.randn(2, 4) # 가중치\n",
    "b1 = np.random.randn(4)   # 편향\n",
    "x = np.random.randn(10, 2)  # 입력값\n",
    "\n",
    "h = np.dot(x, W1) +b1                  #summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLGSMu2xFVHz"
   },
   "source": [
    "### 1) 활성함수로 Sigmoid 함수 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "I0dAknoxLsYp",
    "outputId": "bc73995e-c215-4942-b691-8ec059adecbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52383803, 0.6778346 , 0.06826243, 0.38427205],\n",
       "       [0.34894183, 0.29171666, 0.00992367, 0.65227519],\n",
       "       [0.7107872 , 0.90276753, 0.47932628, 0.16882212],\n",
       "       [0.39927446, 0.76684715, 0.00426766, 0.448821  ],\n",
       "       [0.41605545, 0.20401773, 0.05746921, 0.63396685],\n",
       "       [0.43944745, 0.3295984 , 0.05078928, 0.56583762],\n",
       "       [0.66937248, 0.61487027, 0.64143459, 0.29368248],\n",
       "       [0.54336002, 0.28406798, 0.32768714, 0.49879043],\n",
       "       [0.5442448 , 0.37787183, 0.25190936, 0.46430252],\n",
       "       [0.61497981, 0.16914235, 0.78738125, 0.49221611]])"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9_VKPcaFVH3"
   },
   "source": [
    "### 2) 활성함수로 RELU 함수 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "19g-9JA_L3CS",
    "outputId": "c2500c11-b31c-4572-b12d-d897bc3fc6c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09542446, 0.74383825, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.62905516],\n",
       "       [0.89921034, 2.22836037, 0.        , 0.        ],\n",
       "       [0.        , 1.19059326, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.54927276],\n",
       "       [0.        , 0.        , 0.        , 0.26488855],\n",
       "       [0.70534825, 0.46783105, 0.5815961 , 0.        ],\n",
       "       [0.17387684, 0.        , 0.        , 0.        ],\n",
       "       [0.17744333, 0.        , 0.        , 0.        ],\n",
       "       [0.46829368, 0.        , 1.30921194, 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvF6k4dmFVH4"
   },
   "source": [
    "### 3) 활성함수로 tanh 함수 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "r9z5zaiBL56N",
    "outputId": "12c95510-9857-4f0a-99a3-5f7dc34dab51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09513587,  0.63145854, -0.98932221, -0.43937376],\n",
       "       [-0.55369459, -0.70993918, -0.99979909,  0.55740128],\n",
       "       [ 0.71591316,  0.97706537, -0.08255375, -0.92076011],\n",
       "       [-0.38718904,  0.83076277, -0.99996326, -0.20259339],\n",
       "       [-0.32657315, -0.87671044, -0.99259206,  0.49997496],\n",
       "       [-0.2387092 , -0.61067807, -0.99429038,  0.25886224],\n",
       "       [ 0.60775155,  0.43644518,  0.52382454, -0.7051977 ],\n",
       "       [ 0.1721455 , -0.72795896, -0.61608136, -0.00483824],\n",
       "       [ 0.17560416, -0.46100838, -0.79631347, -0.14206577],\n",
       "       [ 0.43681961, -0.9204123 ,  0.86407588, -0.03112802]])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanh(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FApBMsnOFVH6"
   },
   "source": [
    "# 문제 3. 다음을 서술하시오"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIMu7ZyVFVH7"
   },
   "source": [
    "### 1) Gradient Vanishing의 발생과정을 설명하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmj0VlHbFVH8"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "심층신경망에서 가중치를 Back propagation으로 학습시키는 과정에서 가중치가 발산하거나 곡선의 기울기가 0이되는 것을 기울기 소실(vanishing grdient problem)이라고 한다.\n",
    "시그모이드 함수에서 gradient vanishing 발생과정을 보면, 시그모이드 함수는 0~1을 표현하여 미분값은 0~0.25 사이의 값만 표현가능하다.\n",
    "그래서 역전파로 결과값에 대한 가중치를 계산할 경우 전달되는 값이 1/4 씩 감소되는 현상이 발생한다.\n",
    "따라서 학습이 깊어질수록 0에 가까운 값들이 계속 곱해져서 gradient가 소실되고 결국 학습이 되지 않는 현상이 발생한다.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Md8Wk4AfFVH8"
   },
   "source": [
    "### 2) Dying RELU의 발생과정을 설명하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhaSCZ2eFVH9"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "렐루 함수는 음수를 입력하면 0을 출력하고, 양수를 입력하면 입력값을 그대로 반환한다.\n",
    "그래서 입력값이 음수이면 backpropagation시 기울기가 0이 되며, 따라서 해당 노드가 통째로 죽어버리게 된다.\n",
    "그리고 이 뉴런은 다시 회생하는 것이 매우 어렵다.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "딥러닝_12주차_복습과제.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
